{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bXfrTxCPvSax",
        "outputId": "680d4f49-b151-4c91-8aa1-6e0de9853940",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting unstructured[all-docs]\n",
            "  Downloading unstructured-0.15.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (5.2.0)\n",
            "Collecting filetype (from unstructured[all-docs])\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured[all-docs])\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (4.12.3)\n",
            "Collecting emoji (from unstructured[all-docs])\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dataclasses-json (from unstructured[all-docs])\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting python-iso639 (from unstructured[all-docs])\n",
            "  Downloading python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured[all-docs])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (1.26.4)\n",
            "Collecting rapidfuzz (from unstructured[all-docs])\n",
            "  Downloading rapidfuzz-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured[all-docs])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured[all-docs])\n",
            "  Downloading unstructured_client-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (5.9.5)\n",
            "Collecting pillow-heif (from unstructured[all-docs])\n",
            "  Downloading pillow_heif-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (3.1.5)\n",
            "Collecting google-cloud-vision (from unstructured[all-docs])\n",
            "  Downloading google_cloud_vision-3.7.4-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting unstructured-inference==0.7.36 (from unstructured[all-docs])\n",
            "  Downloading unstructured_inference-0.7.36-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting python-docx>=1.1.2 (from unstructured[all-docs])\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pikepdf (from unstructured[all-docs])\n",
            "  Downloading pikepdf-9.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (2.0.1)\n",
            "Collecting python-pptx<=0.6.23 (from unstructured[all-docs])\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting effdet (from unstructured[all-docs])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting pypandoc (from unstructured[all-docs])\n",
            "  Downloading pypandoc-1.13-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pypdf (from unstructured[all-docs])\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pytesseract (from unstructured[all-docs])\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting onnx (from unstructured[all-docs])\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting python-oxmsg (from unstructured[all-docs])\n",
            "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (3.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (3.6)\n",
            "Collecting pdf2image (from unstructured[all-docs])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[all-docs])\n",
            "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (2.1.4)\n",
            "Collecting pdfminer.six (from unstructured[all-docs])\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting layoutparser (from unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting python-multipart (from unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.23.5)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (4.10.0.84)\n",
            "Collecting onnxruntime>=1.17.0 (from unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (2.3.1+cu121)\n",
            "Collecting timm (from unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading timm-1.0.8-py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (4.42.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.20.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<=0.6.23->unstructured[all-docs])\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[all-docs]) (2.5)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured[all-docs])\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured[all-docs])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[all-docs]) (0.18.1+cu121)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[all-docs]) (2.0.8)\n",
            "Collecting omegaconf>=2.0 (from effdet->unstructured[all-docs])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (2.19.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[all-docs]) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[all-docs]) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[all-docs]) (3.20.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[all-docs]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[all-docs]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[all-docs]) (2024.5.15)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured[all-docs]) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[all-docs]) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[all-docs]) (42.0.8)\n",
            "Collecting pillow\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting Deprecated (from pikepdf->unstructured[all-docs])\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting olefile (from python-oxmsg->unstructured[all-docs])\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[all-docs]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[all-docs]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[all-docs]) (2024.7.4)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured[all-docs])\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx>=0.27.0 (from unstructured-client->unstructured[all-docs])\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured[all-docs])\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from unstructured-client->unstructured[all-docs])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[all-docs]) (1.6.0)\n",
            "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured[all-docs])\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.16.0)\n",
            "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured[all-docs])\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.63.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->unstructured-client->unstructured[all-docs])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[all-docs])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[all-docs])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (6.0.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (1.13.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->unstructured-inference==0.7.36->unstructured[all-docs]) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (3.15.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[all-docs]) (0.19.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (1.13.1)\n",
            "Collecting iopath (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading pdfplumber-0.11.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.6.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting portalocker (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured[all-docs]) (2.1.5)\n",
            "Collecting pdfminer.six (from unstructured[all-docs])\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs])\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (1.3.0)\n",
            "Downloading unstructured_inference-0.7.36-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_cloud_vision-3.7.4-py2.py3-none-any.whl (467 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.5/467.5 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pikepdf-9.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypandoc-1.13-py3-none-any.whl (21 kB)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.25.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.8-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.2-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: langdetect, antlr4-python3-runtime, iopath\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=0030d1deb3128747536a3d5d9ff290ae17082ac682f2603543ff2a71c4b8bdce\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144552 sha256=ba14b52010642d06b16d9fcb0442aa416e4eeb5b70bf87b2ace8d341f667e6ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31531 sha256=28ff51ba506f4a130dfc628aac32bb248c8e6f243b7774887313e783815dc3db\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built langdetect antlr4-python3-runtime iopath\n",
            "Installing collected packages: filetype, antlr4-python3-runtime, XlsxWriter, rapidfuzz, python-multipart, python-magic, python-iso639, python-docx, pypdfium2, pypdf, pypandoc, portalocker, pillow, ordered-set, onnx, omegaconf, olefile, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, langdetect, jsonpath-python, humanfriendly, h11, emoji, Deprecated, backoff, unstructured.pytesseract, typing-inspect, requests-toolbelt, python-pptx, python-oxmsg, pytesseract, pillow-heif, pikepdf, pdf2image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, httpcore, deepdiff, coloredlogs, pdfminer.six, onnxruntime, nvidia-cusolver-cu12, httpx, dataclasses-json, unstructured-client, pdfplumber, unstructured, layoutparser, google-cloud-vision, timm, unstructured-inference, effdet\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed Deprecated-1.2.14 XlsxWriter-3.2.0 antlr4-python3-runtime-4.9.3 backoff-2.2.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 deepdiff-7.0.1 effdet-0.4.1 emoji-2.12.1 filetype-1.2.0 google-cloud-vision-3.7.4 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 humanfriendly-10.0 iopath-0.1.10 jsonpath-python-1.0.6 langdetect-1.0.9 layoutparser-0.3.4 marshmallow-3.21.3 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 olefile-0.47 omegaconf-2.3.0 onnx-1.16.1 onnxruntime-1.18.1 ordered-set-4.1.0 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.2 pikepdf-9.1.0 pillow-10.4.0 pillow-heif-0.18.0 portalocker-2.10.1 pypandoc-1.13 pypdf-4.3.1 pypdfium2-4.30.0 pytesseract-0.3.10 python-docx-1.1.2 python-iso639-2024.4.27 python-magic-0.4.27 python-multipart-0.0.9 python-oxmsg-0.0.1 python-pptx-0.6.23 rapidfuzz-3.9.5 requests-toolbelt-1.0.0 timm-1.0.8 typing-inspect-0.9.0 unstructured-0.15.0 unstructured-client-0.25.0 unstructured-inference-0.7.36 unstructured.pytesseract-0.3.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google",
                  "pydevd_plugins"
                ]
              },
              "id": "9eccb052ab2d448289337c2df5970cf6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install \"unstructured[all-docs]\" pillow pydantic lxml matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY_HQzrvvtzU",
        "outputId": "dfa24a51-e5f7-4ed2-a14d-36e588b8dfa0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [861 kB]\n",
            "Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,217 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,393 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,112 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,421 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,882 kB]\n",
            "Hit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,552 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [49.2 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,130 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,780 kB]\n",
            "Fetched 24.7 MB in 3s (8,111 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libleptonica-dev tesseract-ocr libtesseract-dev python3-pil tesseract-ocr-eng tesseract-ocr-script-latn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6esUxJivveV",
        "outputId": "8dfbb9eb-a8b2-4607-ae49-0e6c51bf2451",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libimagequant0 libraqm0 mailcap mime-support python3-olefile\n",
            "  tesseract-ocr-osd\n",
            "Suggested packages:\n",
            "  python-pil-doc\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libimagequant0 libleptonica-dev libraqm0 libtesseract-dev\n",
            "  mailcap mime-support python3-olefile python3-pil tesseract-ocr\n",
            "  tesseract-ocr-eng tesseract-ocr-osd tesseract-ocr-script-latn\n",
            "0 upgraded, 13 newly installed, 0 to remove and 60 not upgraded.\n",
            "Need to get 40.0 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.1 [582 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libimagequant0 amd64 2.17.0-1 [34.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libraqm0 amd64 0.7.0-4ubuntu1 [11.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-olefile all 0.46-3 [33.8 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-pil amd64 9.0.1-1ubuntu0.3 [419 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-script-latn all 1:4.00~git30-7274cfa-1.1 [30.9 MB]\n",
            "Fetched 40.0 MB in 2s (22.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 13.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 123588 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libarchive-dev_3.6.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libimagequant0:amd64.\n",
            "Preparing to unpack .../01-libimagequant0_2.17.0-1_amd64.deb ...\n",
            "Unpacking libimagequant0:amd64 (2.17.0-1) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../02-libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libraqm0:amd64.\n",
            "Preparing to unpack .../03-libraqm0_0.7.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking libraqm0:amd64 (0.7.0-4ubuntu1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../04-libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../05-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../06-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package python3-olefile.\n",
            "Preparing to unpack .../07-python3-olefile_0.46-3_all.deb ...\n",
            "Unpacking python3-olefile (0.46-3) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../08-python3-pil_9.0.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (9.0.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../09-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../10-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../11-tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package tesseract-ocr-script-latn.\n",
            "Preparing to unpack .../12-tesseract-ocr-script-latn_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-script-latn (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-script-latn (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up python3-olefile (0.46-3) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libraqm0:amd64 (0.7.0-4ubuntu1) ...\n",
            "Setting up libimagequant0:amd64 (2.17.0-1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up python3-pil:amd64 (9.0.1-1ubuntu0.3) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured-pytesseract\n",
        "!pip install tesseract-ocr"
      ],
      "metadata": {
        "id": "UI6goId2vva6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3d4bb7-70d9-4a88-c6af-bcc7c7886437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unstructured-pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from unstructured-pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-pytesseract) (10.4.0)\n",
            "Collecting tesseract-ocr\n",
            "  Downloading tesseract-ocr-0.0.1.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from tesseract-ocr) (3.0.10)\n",
            "Building wheels for collected packages: tesseract-ocr\n",
            "  Building wheel for tesseract-ocr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract-ocr: filename=tesseract_ocr-0.0.1-cp310-cp310-linux_x86_64.whl size=169750 sha256=2df7153c07f1b61d320995e44ecc719fae1cd88fa7e810d68f6d2a69590eedf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/fd/f3/5c231ecbbb80a1fe33204ff3021d99b54ef6daf6f8099311b8\n",
            "Successfully built tesseract-ocr\n",
            "Installing collected packages: tesseract-ocr\n",
            "Successfully installed tesseract-ocr-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from unstructured.partition.pdf import partition_pdf"
      ],
      "metadata": {
        "id": "fxU8c4zXvvY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpTPlyYk024m",
        "outputId": "630d0ac3-e386-4c6a-ecc5-f7576a5dc5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 60 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 1s (313 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123930 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_elements=partition_pdf(\n",
        "    filename=\"/content/content/03.0724 Lime diseases classification Using ML and (1).pdf\",\n",
        "    strategy=\"hi_res\",\n",
        "    extract_images_in_pdf=True,\n",
        "    extract_image_block_types=[\"Image\", \"Table\"],\n",
        "    extract_image_block_to_payload=False,\n",
        "    extract_image_block_output_dir=\"extracted_data\"\n",
        "  )"
      ],
      "metadata": {
        "id": "xjqvQ3havvWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_pdf_elements"
      ],
      "metadata": {
        "id": "OUGno3q7vvT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "d0847b57-f1b2-4287-e7ac-88be314f8747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.Title at 0x7ec431a6e770>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4341698a0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec434168a00>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec434168ee0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec43416b1f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec43416b160>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6e230>,\n",
              " <unstructured.documents.elements.Title at 0x7ec434169510>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec434169420>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4341699f0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6c130>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6e1a0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6e830>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6f2b0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6ccd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6e620>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6fd00>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6d480>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6d180>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6d420>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6eec0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6ea40>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6e6e0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6f550>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6ed10>,\n",
              " <unstructured.documents.elements.Table at 0x7ec431a6f5b0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6d720>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6d090>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6dc00>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6c5b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6d8d0>,\n",
              " <unstructured.documents.elements.Image at 0x7ec431a6d330>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6d450>,\n",
              " <unstructured.documents.elements.Image at 0x7ec431a6f3a0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6eb60>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6f400>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6e8f0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6ec20>,\n",
              " <unstructured.documents.elements.Image at 0x7ec4341483a0>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7ec43414b640>,\n",
              " <unstructured.documents.elements.Image at 0x7ec43414b5b0>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7ec434149ff0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec43414a050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec434149060>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6fa00>,\n",
              " <unstructured.documents.elements.Image at 0x7ec4341814b0>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7ec434180a60>,\n",
              " <unstructured.documents.elements.Image at 0x7ec434182260>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7ec434182590>,\n",
              " <unstructured.documents.elements.Title at 0x7ec434181b40>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431cc64d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc6680>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc65f0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6e7a0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc4bb0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc6980>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc6e60>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc69b0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6d5d0>,\n",
              " <unstructured.documents.elements.Table at 0x7ec431cc6950>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431cc70a0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431cc5ab0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc79d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc77c0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc7520>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6df30>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431cc5960>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6e980>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a6f4f0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a6d9c0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6d570>,\n",
              " <unstructured.documents.elements.Table at 0x7ec431cc7af0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431cc7430>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec43420e050>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec43420dc60>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec43420e5c0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec43420ec80>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec43420ee90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec43420f100>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec43420e410>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6d630>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6f880>,\n",
              " <unstructured.documents.elements.Table at 0x7ec434277a90>,\n",
              " <unstructured.documents.elements.Title at 0x7ec4342767d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec434276f20>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a6ea10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec433c1d7e0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec433c1ec80>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec434168b50>,\n",
              " <unstructured.documents.elements.Table at 0x7ec434169fc0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6d9f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec434274370>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a6cd00>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6ece0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a6fe80>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec4342754b0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434274460>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434275d50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec4342778e0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a6f8e0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a6f1f0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434275930>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434274d30>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434276470>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434277250>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a6c490>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec433df7d60>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec433df5db0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec433df5b10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a6fcd0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec433df5060>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a6dd50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec433df7550>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec433df4c10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec433df6110>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Header=[]\n",
        "Footer=[]\n",
        "Title=[]\n",
        "NarrativeText=[]\n",
        "Text=[]\n",
        "ListItem=[]\n",
        "\n",
        "\n",
        "for element in raw_pdf_elements:\n",
        "  if \"unstructured.documents.elements.Header\" in str(type(element)):\n",
        "            Header.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Footer\" in str(type(element)):\n",
        "            Footer.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
        "            Title.append(str(element))\n",
        "  elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
        "            NarrativeText.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Text\" in str(type(element)):\n",
        "            Text.append(str(element))\n",
        "  elif \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
        "            ListItem.append(str(element))\n",
        "\n"
      ],
      "metadata": {
        "id": "PND25RlovvRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NarrativeText"
      ],
      "metadata": {
        "id": "eFRukFEhvvPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "801d025a-56d8-439c-d99c-858eeeac48e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Abhay Nath1 [0009-0007-2843-5777], Pratishtha Makhijani2[0009-0002-4216-4655], Hasti Vakani3[0009-0006- 5905-1007] , Mithil Mistry4[0009-0000-7055-6088], Hardi Koradiya5[0009-0003-7957-9229] , Hardikkumar S. Jayswa1 6[0000-0002-2224-5258] , Dr. Jitendra P. Chaudhari7 [0000-0002-7070-093X] Mr. Axat Patel8[0000-0003-0441-6057], Dr. Nilesh Dubey9 [0000-0002-3105-9465]',\n",
              " 'jayswal.hardik.kumar@gmail.com',\n",
              " '1,5,6 Department of Information Technology, Devang Patel institute of advanced technology and Research , Charotar University of Science and Technology Anand (Gujarat), India 2,3,4,9 Department of Computer Science & Engineering, Devang Patel institute of advanced technology and Research , Charotar University of Science and Technology Anand (Gujarat),India 7,8Charusat Space Research and Technology Center,Charotar University of Science and Technology Anand (Gujarat), India',\n",
              " 'Abstract. This study explores the classification of lime diseases using advanced machine learning models and spectrometry data, aiming to improve the accuracy and reliability of disease diagnostics in agriculture. Lime diseases such as citrus canker and citrus black spot cause significant economic losses and challenge traditional visual inspection methods due to their complexity and rapid spread. We utilized Long Short-Term Memory (LSTM), Recurrent Neural Network (RNN), and Bidirectional LSTM (BiLSTM) networks to analyze sequential spectrometry data. These models were further combined with various classifiers, including SVM, KNN, and XGBoost, to enhance the precision of disease detection. The LSTM model alone achieved a precision of 99.96%, while the RNN and BiLSTM models reached 99.4113% and 99.9206%, respectively. Integrating BiLSTM features with classifiers resulted in even higher precision, up to 99.9816%. Our models also excelled in sensitivity and specificity, with the BiLSTM model achieving 99.96% sensitivity and 99.78% specificity. These metrics substantially surpass the results from previous studies, which reported 90.5% sensitivity and 87.0% specificity. This improvement highlights the superior ability of our approach to accurately identify and classify lime diseases. Overall, our research demonstrates that combining deep learning models with traditional classifiers significantly enhances the precision and efficiency of lime disease diagnostics. This advancement is crucial for effective disease management, leading to improved crop protection and economic resilience in the agricultural sector.',\n",
              " 'Keywords: Machine Learning, Long Short-Term Memory (LSTM), Recurrent Neural Network (RNN), Bidirectional LSTM (BiLSTM)',\n",
              " \"Agriculture has long been understood to have a crucial role in development. According to the seminal research on the topic, agriculture made contributions that aided in the development of industry and the structural upheaval of the economy [1]. Especially for a country like India where the economy is heavily dependent on agriculture, with over 58% of rural households using it as their primary source of income, crop protection acts a cornerstone for the economy and sustenance for millions. But, worldwide plant diseases have caused significant financial losses for the agriculture sector. According to a report published by The Food and Agriculture Organization (FAO), different pests and diseases may cause 40% of the world's crops to be lost annually. Given the demands of an expanding human population, the difficulties posed by climate change, this is quite concerning [2]. The typical method of studying plant disease is to rely on visually observable patterns on the plant leaves. The excessive variety of plants, variations in the course of plant diseases due to climate changes and the faster spread of diseases to other regions where they have not been seen before, even lead experienced pathologists fail to diagnose certain diseases. Therefore, it is crucial to have a quick, automated, and precise way to identify plant diseases [3].\",\n",
              " 'Citrus production and cultivation are threatened continuously by many challenges such as pathogens, pests and diseases that lead to considerable economic losses [4]. The bacterial, fungal, and viral infections, along with infestations by insects result in plant diseases and damage. The agricultural diseases that infect citrus plants are citrus bacterial canker (CBC), citrus black spot (CBS) and Citrus huanglongbing (HLB), also known as yellow dragon disease [5]. Plant disease detection and classification have made extensive use of computer vision and machine learning in recent years, opening up prospects for early disease diagnosis. Various techniques used for detection of plant diseases include spectroscopic and imaging techniques for disease detection, and Molecular techniques of plant disease detection and spectroscopy [6][28]. Furthermore, spectroscopy can be classified into three categories: vibrational, visible, and infrared. Vibrational spectroscopy encompasses methods like Raman and infrared (IR) spectroscopy, which probe the vibrational states of molecules, providing insights into their molecular structure and chemical bonds [7]. Visible spectroscopy explores the absorption and emission of light in the visible spectrum, often used in determining the concentration of compounds in solutions through colorimetric methods [8]. Infrared spectroscopy delves into the absorption of infrared light by molecules, providing detailed information about molecular structures and bonds by analyzing the characteristic vibrational modes of chemical bonds [9] This research aims to significantly advance the classification of lime diseases by surpassing the performance of prior studies. While previous research achieved accuracies around 90% to 96% and reported sensitivities of 90.5% and specificities of 87.0%, our study exceeds these benchmarks by attaining over 99% in precision, sensitivity, and specificity. By utilizing sophisticated models such as LSTM, RNN, and BiLSTM combined with various classifiers, we demonstrate a highly efficient approach to accurately distinguishing',\n",
              " 'between normal and diseased lime leaves, thereby enhancing the precision and reliability of disease diagnostics in agriculture',\n",
              " 'In North America and Europe, Lyme disease is the most prevalent infectious disease spread by vectors [10]. In particular, if the early disease presentation is overlooked, prompt diagnosis is essential to stop the disease from progressing. However, the sensitivity of the current Lyme disease tests is low (less than 50%) for early presentations. To improve clinical performance, one group has developed a multiplex POC sero-diagnostic test that targets antigens OspC, BmpA, P41, ErpD, Crasp1, OspA, DbpB, VlsE, P35, and Mod-C6 improved by ML. The test has a reported 87.0% specificity and 90.5% sensitivity [11]. Least Absolute Shrinkage and Selection Operator (LASSO) statistical modeling was utilized by the classification tools, and it worked effectively when data was collected concurrently. However, when temporal disparities were present, test accuracy suffered, maybe as a result of normalization techniques and sparsity parameters [12].',\n",
              " 'In the process of evaluating and comparing various methods for disease detection in citrus plants, it is essential to examine previous studies that have utilized different techniques and achieved varying levels of accuracy. For instance, the study titled \"Lime Diseases Detection and Classification Using Spectroscopy and Computer Vision\" utilized spectral-based sensing combined with a K-Nearest Neighbors (KNN) algorithm. This method achieved impressive accuracy rates, with imaging techniques reaching 96% and non- imaging techniques achieving up to 99% accuracy [13].',\n",
              " 'Similarly, the paper \"Citrus Leaf Unhealthy Region Detection by Using Image Processing Technique\" implemented a series of image preprocessing steps, including normalization, contrast adjustment, bi-level thresholding, and darken mutate in the YCbCr color space. The classification was conducted using a Hidden Markov Model (HMM), resulting in an overall accuracy of 92.3% [14].',\n",
              " 'Another notable approach is documented in \"Citrus Leaf Disease Detection and Classification Using Hierarchical Support Vector Machine,\" where a',\n",
              " 'hierarchical support vector machine (SVM) was utilized. This technique yielded an accuracy of 91.76% in classifying various citrus leaf diseases [29].',\n",
              " 'In a different context, the study \"Detecting Myrtle Rust (Austropuccinia psidii) on Lemon Myrtle Trees Using Spectral Signatures and Machine Learning\" applied a random forest classifier to detect myrtle rust. The method achieved a lower accuracy of 78%, reflecting the challenges associated with this particular disease and dataset [16].',\n",
              " 'Table 1. PREVIOUS RESEARCH RESULTS USING DIFFERENT METHODS',\n",
              " 'We endorse precision over accuracy in our model evaluations due to the imbalanced nature of our dataset, which consists of over 2,000 parameters from normal leaves and over 8,000 parameters from diseased leaves. Our approach combines Long Short-Term Memory (LSTM) networks, Recurrent Neural Network (RNN) and Bidirectional LSTM (BiLSTM) with various classifiers to enhance the performance of the model. Below, we describe the specific methodologies and classifiers used.',\n",
              " 'We utilized an LSTM network as the primary model for feature extraction due to its effectiveness in handling sequential data. The LSTM model was designed to capture temporal dependencies and intricate patterns in the spectrometry data [17][15]. The precision for this model was 99.96%.',\n",
              " 'Fig. 1. It displays the training and validation accuracy , training and validation loss graph using LSTM network.',\n",
              " 'We also explored the use of a traditional Recurrent Neural Network (RNN) for feature extraction. RNNs are designed to handle sequential data by maintaining a hidden state that captures information about previous inputs in the sequence. This capability allows RNNs to identify patterns over time within the spectrometry data [18]. The precision for the RNN model was 99.4113%.',\n",
              " 'We also implemented a Bidirectional Long Short-Term Memory (BiLSTM) network to enhance feature extraction from the spectrometry data. The BiLSTM architecture extends the standard LSTM by processing the sequence data in both forward and backward directions. This dual approach enables the network to capture information from past and future states simultaneously, providing a more comprehensive understanding of the sequential patterns in the data [19]. The precision achieved by the BiLSTM model was 99.9206%, demonstrating its strong capability in handling the intricate and sequential nature of the spectrometry data.',\n",
              " 'After training the LSTM network, the extracted features from the LSTM were fed into various classifiers to improve precision in detecting diseased leaves. We evaluated the performance of the features with different classifiers as follows:',\n",
              " 'After training the RNN network, the extracted features from the RNN were fed into various classifiers to improve precision in detecting diseased leaves. We evaluated the performance of the features with different classifiers as follows:',\n",
              " 'with XGBoost yielded a precision of 99.8813%. RNN with Decision Tree Classifier: The precision obtained by the RNN combined with the Decision Tree classifier was 99.8423%. RNN with Support Vector Machine (SVM) Classifier: The RNN combined with the SVM classifier achieved a precision of 99.9022%.',\n",
              " 'After training the BiLSTM network, the extracted features from the BiLSTM were fed into various classifiers to improve precision in detecting diseased leaves. We evaluated the performance of the features with different classifiers as follows:',\n",
              " 'In our research we focused on evaluating sensitivity and specificity to effectively handle the imbalanced dataset and ensure accurate identification of diseased and normal leaves [26]. These metrics are critical because high sensitivity minimizes the risk of missing diseased leaves, while high specificity reduces false positives, which are essential for efficient disease management and cost control [27].',\n",
              " 'These results significantly surpass the previous studies, which reported 90.5% sensitivity and 87.0% specificity in lime disease classification studies, highlighting the advanced capabilities of LSTM, RNN, and BiLSTM models in extracting and utilizing complex patterns from spectrometry data. This improvement is crucial for more accurate and reliable disease diagnostics in agricultural settings.',\n",
              " 'Table 5. SENSITIVITY AND SPECIFICITY METRICS FOR ALL MODELS',\n",
              " 'Conclusions and Future Work This study demonstrates the superior capability of combining advanced machine learning models like LSTM, RNN, and BiLSTM with various classifiers in classifying lime diseases using spectrometry data. Achieving over 99% in precision, sensitivity, and specificity, our approach significantly outperforms previous studies. This enhanced accuracy is crucial for effective disease management, offering a reliable tool for early and precise detection of lime diseases. The findings underscore the potential of integrating deep learning and spectrometry to revolutionize agricultural diagnostics and mitigate economic losses due to plant diseases',\n",
              " 'Anríquez, G., & Stamoulis, K. G. (2007). Rural Development and Poverty Reduction: Is Agriculture Still Key?. eJADE: electronic Journal of Agricultural and Development Economics, 4(1), 5-46. Savary, S., Ficke, A., Aubertot, J. N., & Hollier, C. (2012). Crop losses due to diseases and their implications for global food production losses and food security. Food security, 4(4), 519-537. Ferentinos, K. P. (2018). Deep learning models for plant disease detection and diagnosis. Computers and electronics in agriculture, 145, 311-318. Martinelli, F., Scalenghe, R., Davino, S., Panno, S., Scuderi, G., Ruisi, P., ... & Dandekar, A. M. (2015). Advanced methods of plant disease detection. A review. Agronomy for Sustainable Development, 35, 1-25. Syed-Ab-Rahman, S. F., Hesamian, M. H., & Prasad, M. (2022). Citrus disease detection and classification using end-to-end anchorbased deep learning model. Applied Intelligence, 52(1), 927-938. Singh, V., Sharma, N., & Singh, S. (2020). A review of imaging techniques for plant disease detection. Artificial Intelligence in Agriculture, 4, 229-242. Sathyanarayana, D. N. (2015). Vibrational spectroscopy: theory and applications. New Age International. Brown, J. Q., Vishwanath, K., Palmer, G. M., & Ramanujam, N. (2009). Advances in quantitative UV–visible spectroscopy for clinical and pre-clinical application in cancer. Current opinion in biotechnology, 20(1), 119-131. Noda, I. (1989). Two-dimensional infrared spectroscopy. Journal of the American Chemical Society, 111(21), 8116-8118.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=[]\n",
        "for element in raw_pdf_elements:\n",
        "  if \"unstructured.documents.elements.Image\" in str(type(element)):\n",
        "            img.append(str(element))"
      ],
      "metadata": {
        "id": "gmBGAF-8vvMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img[1]"
      ],
      "metadata": {
        "id": "S3J27Kg_vvKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "866d2497-1cd6-4fe9-ed8a-5a3115a1ff4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LSTM Model - Confusion Matrix | 2000 1500 - 1000 Healthy Predicted Label'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_pdf_elements2=partition_pdf(\n",
        "    filename=\"/content/content/03.0724 Lime diseases classification Using ML and (1).pdf\",\n",
        "    strategy=\"hi_res\",\n",
        "    extract_images_in_pdf=True,\n",
        "    extract_image_block_types=[\"Image\", \"Table\"],\n",
        "    extract_image_block_to_payload=False,\n",
        "    extract_image_block_output_dir=\"extracted_data2\"\n",
        "  )"
      ],
      "metadata": {
        "id": "B0xeRzvfvvIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_pdf_elements2"
      ],
      "metadata": {
        "id": "8DW9aEAUvvFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "20874453-133e-4899-87d7-8069f9616e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.Title at 0x7ec44477ec80>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e7e80>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e4250>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e4880>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e4e20>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e49a0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec44477e440>,\n",
              " <unstructured.documents.elements.Title at 0x7ec4311e5360>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e5630>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e5b70>,\n",
              " <unstructured.documents.elements.Text at 0x7ec446292f50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e5c60>,\n",
              " <unstructured.documents.elements.Title at 0x7ec4311e6050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e5f60>,\n",
              " <unstructured.documents.elements.Title at 0x7ec4311e6230>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e6590>,\n",
              " <unstructured.documents.elements.Title at 0x7ec4311e64a0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e6680>,\n",
              " <unstructured.documents.elements.Title at 0x7ec4311e6770>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e6b00>,\n",
              " <unstructured.documents.elements.Text at 0x7ec4462927a0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e6ce0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec4311e7040>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e6f50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e7130>,\n",
              " <unstructured.documents.elements.Table at 0x7ec4311e7580>,\n",
              " <unstructured.documents.elements.Title at 0x7ec4311e7670>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec4311e7760>,\n",
              " <unstructured.documents.elements.Text at 0x7ec4581cfe20>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431192020>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431192e60>,\n",
              " <unstructured.documents.elements.Image at 0x7ec431192410>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431193370>,\n",
              " <unstructured.documents.elements.Image at 0x7ec4343e9fc0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec446292f80>,\n",
              " <unstructured.documents.elements.Title at 0x7ec434169cc0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec43416b670>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a8cb20>,\n",
              " <unstructured.documents.elements.Image at 0x7ec434181390>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7ec434180f70>,\n",
              " <unstructured.documents.elements.Image at 0x7ec434180760>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7ec431b13460>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431b12fe0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431b102e0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a8fe80>,\n",
              " <unstructured.documents.elements.Image at 0x7ec431b117e0>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7ec431b12fb0>,\n",
              " <unstructured.documents.elements.Image at 0x7ec431b13910>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7ec431b12dd0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431b130a0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431b12290>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b10970>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b131f0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a8ff10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b13dc0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b13d30>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b12ce0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b11270>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a8c100>,\n",
              " <unstructured.documents.elements.Table at 0x7ec431b112d0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431b10430>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431b10cd0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b10e50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b12cb0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b10f70>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a8fd60>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431b11db0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a8d540>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a8f490>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a8f520>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a8e1a0>,\n",
              " <unstructured.documents.elements.Table at 0x7ec431b120b0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431b12560>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a9bbe0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a99ba0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9a0b0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9a980>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9b100>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9a350>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9be20>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a8e3b0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a8e1d0>,\n",
              " <unstructured.documents.elements.Table at 0x7ec431a98190>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a9b6a0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a9ba60>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a8c0d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a99c30>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a99930>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a999c0>,\n",
              " <unstructured.documents.elements.Table at 0x7ec431a99600>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a8e410>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a99bd0>,\n",
              " <unstructured.documents.elements.Title at 0x7ec431a8f5b0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a8dfc0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7ec431a8dc00>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a984c0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a989a0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9bf70>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9a2f0>,\n",
              " <unstructured.documents.elements.Text at 0x7ec431a8e140>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a8cf10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9aaa0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9b880>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9a530>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a99ea0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a8d930>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a98880>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a9b4f0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec4342408b0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a8d120>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec4342435b0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec431a8d0f0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434241f30>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434241f60>,\n",
              " <unstructured.documents.elements.ListItem at 0x7ec434243a00>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=[]\n",
        "for element in raw_pdf_elements2:\n",
        "  if \"unstructured.documents.elements.Image\" in str(type(element)):\n",
        "            img.append(str(element))\n",
        "\n",
        "\n",
        "img"
      ],
      "metadata": {
        "id": "nEv9BcZOvvDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17180815-25c5-4d47-ba7d-8df85be9fa14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'LSTM Model - Confusion Matrix | 2000 1500 - 1000 Healthy Predicted Label',\n",
              " '',\n",
              " 'RNN Model - Confusion Matrix 2500 | 2000 Healthy 1500 True Label - 1000 Diseased Healthy Diseased Predicted Label',\n",
              " '',\n",
              " 'Bi-LSTM Model - Confusion Matrix 2000 Healthy 21000 Diseased Healtny Diseased Predicted Label']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tab=[]\n",
        "for element in raw_pdf_elements2:\n",
        "  if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "            tab.append(str(element))\n",
        "\n",
        "\n",
        "tab[0]\n"
      ],
      "metadata": {
        "id": "s65fN_O9vvBf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b9bbceb6-66d5-424d-a391-927bc601d33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Paper Diseases and Lime Detection Classification Using Spectroscopy and Computer Vision Methodology Spectral based sensing, KNN Citrus region detection by using image processing technique leaf unhealthy Normalization and contrast adjustment, Bilevel Thresholding, Darken Mutate YCbCr, classification using Hidden Markov Model (HMM) Citrus leaf disease detection and classification using hierarchical support vector machine Detecting myrtle rust (Austropuccinia psidii) on lemon myrtle trees using spectral signatures and machine learning Hierarchical SVM classification Random forest classifier Accuracy Imaging: 96% Non- imaging: 99% 92.3% 91.76% 78%'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NarrativeText=[]\n",
        "for element in raw_pdf_elements2:\n",
        "  if \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
        "            NarrativeText.append(str(element))\n",
        "\n",
        "\n",
        "ListItem=[]\n",
        "for element in raw_pdf_elements2:\n",
        "  if \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
        "            ListItem.append(str(element))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5L8bdUFYvu-5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install langchain_openai\n",
        "len(tab)"
      ],
      "metadata": {
        "id": "WH-eZKLXvu8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "311ff4c5-5af1-40e6-94be-cafa3a3321ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.24 (from langchain_openai)\n",
            "  Downloading langchain_core-0.2.25-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting openai<2.0.0,>=1.32.0 (from langchain_openai)\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain_openai) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.24->langchain_openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3.0,>=0.2.24->langchain_openai)\n",
            "  Downloading langsmith-0.1.94-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain_openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.24->langchain_openai)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.24->langchain_openai)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.24->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.24->langchain_openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Downloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.25-py3-none-any.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.6/377.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.94-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: orjson, jsonpointer, tiktoken, jsonpatch, openai, langsmith, langchain-core, langchain_openai\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.25 langchain_openai-0.1.19 langsmith-0.1.94 openai-1.37.1 orjson-3.10.6 tiktoken-0.7.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tab[0]\n",
        "\n",
        "len(img)"
      ],
      "metadata": {
        "id": "mljJJ3H2vuu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fa26eb-821d-40be-8915-20b70b6049f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiR91oHyHf6C",
        "outputId": "5fd7e51b-52df-42b7-bb99-2b4d1247c3df",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.25)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.94)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (3.0.0)\n",
            "Downloading langchain-0.2.11-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: langchain-text-splitters, langchain\n",
            "Successfully installed langchain-0.2.11 langchain-text-splitters-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "id": "HDx_zs3iyQJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBZ9BmzzZLroip7ih27zV1mBC2Ekja4Dio\"\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "3lrVyfAxvual"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"\"\"You are an assistant tasked with summarizing tables for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw table elements. \\\n",
        "    Give a concise summary of the table that is well optimized for retrieval. Table {element} \"\"\"\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(prompt_text)"
      ],
      "metadata": {
        "id": "CeKeyqD8wm-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91yWLTcSHsEn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "'''from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] =\"sk-None-QrLM6uyAUAqw17iCgjRFT3BlbkFJzxxn0mIEPpNYjO6WDQEO\"\n",
        "\n",
        "\n",
        "# Text summary chain\n",
        "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "'''\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        "\n",
        "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
        "\n",
        "\n",
        "table_summaries = []\n",
        "\n",
        "\n",
        "#table_summaries=summarize_chain.batch(tab,{\"max_concurrency\": 5})\n",
        "\n",
        "\n",
        "tab[0]"
      ],
      "metadata": {
        "id": "Pu6p97Twwm7G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4066f11c-b643-4e75-e4d8-281579a15cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Paper Diseases and Lime Detection Classification Using Spectroscopy and Computer Vision Methodology Spectral based sensing, KNN Citrus region detection by using image processing technique leaf unhealthy Normalization and contrast adjustment, Bilevel Thresholding, Darken Mutate YCbCr, classification using Hidden Markov Model (HMM) Citrus leaf disease detection and classification using hierarchical support vector machine Detecting myrtle rust (Austropuccinia psidii) on lemon myrtle trees using spectral signatures and machine learning Hierarchical SVM classification Random forest classifier Accuracy Imaging: 96% Non- imaging: 99% 92.3% 91.76% 78%'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"\"\"You are an assistant tasked with summarizing text for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw text elements. \\\n",
        "    Give a concise summary of the table or text that is well optimized for retrieval.text: {element} \"\"\"\n"
      ],
      "metadata": {
        "id": "XZk2YURTwm4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(prompt_text)"
      ],
      "metadata": {
        "id": "oPScUjXZwm2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        "\n",
        "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "btEmi7Wlwmzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summaries = []"
      ],
      "metadata": {
        "id": "Wi1G68ZDwmxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #text_summaries = summarize_chain.batch(Text, {\"max_concurrency\": 5})\n",
        "\n",
        "# !pip install tenacity\n",
        "# import time\n",
        "# import random\n",
        "# from google.api_core.exceptions import ResourceExhausted  # Import ResourceExhausted\n",
        "\n",
        "# def batch_with_retry(summarize_chain, Text, max_retries=5, initial_delay=5, max_concurrency=5):\n",
        "#     retries = 0\n",
        "#     delay = initial_delay\n",
        "#     while retries < max_retries:\n",
        "#         try:\n",
        "#             # Attempt to batch process the texts\n",
        "#             text_summaries = summarize_chain.batch(Text, {\"max_concurrency\": max_concurrency})\n",
        "#             return text_summaries\n",
        "#         except ResourceExhausted as e:  # Now you can catch ResourceExhausted errors\n",
        "#             # Handle ResourceExhausted error\n",
        "#             print(f\"ResourceExhausted error: {e}. Retrying in {delay} seconds...\")\n",
        "#             time.sleep(delay)\n",
        "#             retries += 1\n",
        "#             delay = min(delay * 2, 60)  # Exponential backoff, cap at 60 seconds\n",
        "#         except Exception as e:\n",
        "#             # Handle other exceptions (including InternalServerError)\n",
        "#             print(f\"An error occurred: {e}. Retrying in {delay} seconds...\")\n",
        "#             time.sleep(delay)\n",
        "#             retries += 1\n",
        "#             delay = min(delay * 2, 60)\n",
        "\n",
        "# raise Exception(\"Max retries exceeded\")\n",
        "\n",
        "# # Example usage\n",
        "# text_summaries = batch_with_retry(summarize_chain, Text)\n",
        "import time\n",
        "from google.api_core.exceptions import ResourceExhausted\n",
        "\n",
        "def batch_with_retry(summarize_chain, Text, max_retries=5, initial_delay=5, max_concurrency=5):\n",
        "    retries = 0\n",
        "    delay = initial_delay\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            text_summaries = summarize_chain.batch(Text, {\"max_concurrency\": max_concurrency})\n",
        "            return text_summaries\n",
        "        except ResourceExhausted as e:\n",
        "            print(f\"ResourceExhausted error: {e}. Retrying in {delay} seconds...\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}. Retrying in {delay} seconds...\")\n",
        "        time.sleep(delay)\n",
        "        retries += 1\n",
        "        delay = min(delay * 2, 60)\n",
        "\n",
        "    raise Exception(\"Max retries exceeded\")\n"
      ],
      "metadata": {
        "id": "Hw7DjVSTwmgd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFzr5hi0DWs4",
        "outputId": "027993c9-710b-4e0b-a870-967b334aab72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import base64\n",
        "import os\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "D0l9vQFVDWpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image(image_path):\n",
        "    \"\"\"Getting the base64 string\"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "_F_WRDJ4DWm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "collapsed": true,
        "id": "8--4ig6fJ0ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_summarize(img_base64, prompt):\n",
        "    \"\"\"Make image summary\"\"\"\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-pro\",\n",
        "        temperature=0,\n",
        "        max_tokens=None,\n",
        "        timeout=None,\n",
        "        max_retries=2,\n",
        "        # other params...\n",
        "    )\n",
        "\n",
        "    msg = model.invoke(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"},\n",
        "                    },\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    return msg.content"
      ],
      "metadata": {
        "id": "CfKJA1XHDWkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_img_summaries(path):\n",
        "#     \"\"\"Generate summaries and base64 encoded strings for images\n",
        "#     path: Path to list of .jpg files extracted by Unstructured\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Store base64 encoded images\n",
        "#     img_base64_list = []\n",
        "\n",
        "#     # Store image summaries\n",
        "#     image_summaries = []\n",
        "\n",
        "#     # Prompt\n",
        "#     prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
        "#     These summaries will be embedded and used to retrieve the raw image. \\\n",
        "#     Give a concise summary of the image that is well optimized for retrieval.\"\"\"\n",
        "\n",
        "#     # Apply to images\n",
        "#     for img_file in sorted(os.listdir(path)):\n",
        "#         if img_file.endswith(\".jpg\"):\n",
        "#             img_path = os.path.join(path, img_file)\n",
        "#             base64_image = encode_image(img_path)\n",
        "#             img_base64_list.append(base64_image)\n",
        "#             image_summaries.append(image_summarize(base64_image, prompt))\n",
        "\n",
        "\n",
        "#     return img_base64_list, image_summaries\n",
        "def generate_img_summaries(path, max_retries=5, initial_delay=5):\n",
        "    img_base64_list = []\n",
        "    image_summaries = []\n",
        "    prompt = \"You are an assistant tasked with summarizing images for retrieval. Give a concise summary of the image that is well optimized for retrieval.\"\n",
        "\n",
        "    for img_file in sorted(os.listdir(path)):\n",
        "        if img_file.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(path, img_file)\n",
        "            base64_image = encode_image(img_path)\n",
        "            img_base64_list.append(base64_image)\n",
        "\n",
        "            # Retry logic for image summarization\n",
        "            retries = 0\n",
        "            delay = initial_delay\n",
        "            while retries < max_retries:\n",
        "                try:\n",
        "                    summary = image_summarize(base64_image, prompt)\n",
        "                    image_summaries.append(summary)\n",
        "                    break\n",
        "                except ResourceExhausted as e:\n",
        "                    print(f\"ResourceExhausted error: {e}. Retrying in {delay} seconds...\")\n",
        "                except Exception as e:\n",
        "                    print(f\"An error occurred: {e}. Retrying in {delay} seconds...\")\n",
        "\n",
        "                time.sleep(delay + random.uniform(0, 1))  # Add jitter\n",
        "                retries += 1\n",
        "                delay = min(delay * 2, 60)\n",
        "\n",
        "            if retries == max_retries:\n",
        "                print(f\"Failed to summarize image: {img_path}. Max retries exceeded.\")\n",
        "\n",
        "    return img_base64_list, image_summaries"
      ],
      "metadata": {
        "id": "e0-PRs0WDWiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpath=\"/content/extracted_data2\""
      ],
      "metadata": {
        "id": "7Lm8-w7MDWau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aQ3iaA16JA1l",
        "outputId": "e792ccc3-9a08-4fb0-b8a1-fc42cd604ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.18.1)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.6)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
            "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Collecting importlib-metadata<=8.0.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Downloading chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=1d1e0fa2909763af8a875bf51af0267721d0759896c966ce94ec7b0d38ec7492\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, python-dotenv, overrides, opentelemetry-util-http, opentelemetry-proto, importlib-metadata, httptools, dnspython, chroma-hnswlib, bcrypt, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, email_validator, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.2.0\n",
            "    Uninstalling importlib_metadata-8.2.0:\n",
            "      Successfully uninstalled importlib_metadata-8.2.0\n",
            "Successfully installed asgiref-3.8.1 bcrypt-4.2.0 chroma-hnswlib-0.7.6 chromadb-0.5.5 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 httptools-0.6.1 importlib-metadata-8.0.0 kubernetes-30.1.0 mmh3-4.1.0 monotonic-1.6 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.37.2 uvicorn-0.30.3 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Image summaries\n",
        "img_base64_list, image_summaries = generate_img_summaries(fpath)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2ZDnvUQDWVY",
        "outputId": "07f2624f-31c5-4eec-b3bc-69ea19150f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResourceExhausted error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 5 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResourceExhausted error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 10 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResourceExhausted error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 5 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResourceExhausted error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 10 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResourceExhausted error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 20 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResourceExhausted error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 40 seconds...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import google.generativeai\n",
        "# def create_multi_vector_retriever(vectorstore, text_summaries, texts, table_summaries, tables, image_summaries, images):\n",
        "#     \"\"\"\n",
        "#     Create retriever that indexes summaries, but returns raw images or texts\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Initialize the storage layer\n",
        "#     store = InMemoryStore()\n",
        "#     id_key = \"doc_id\"\n",
        "\n",
        "#     # Create the multi-vector retriever\n",
        "#     retriever = MultiVectorRetriever(\n",
        "#         vectorstore=vectorstore,\n",
        "#         docstore=store,\n",
        "#         id_key=id_key,\n",
        "#     )\n",
        "\n",
        "\n",
        "#     # Helper function to add documents to the vectorstore and docstore\n",
        "#     def add_documents(retriever, doc_summaries, doc_contents):\n",
        "\n",
        "#       doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
        "\n",
        "#       summary_docs = [\n",
        "#               Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "#               for i, s in enumerate(doc_summaries)\n",
        "#           ]\n",
        "\n",
        "#       retriever.vectorstore.add_documents(summary_docs)\n",
        "#       retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
        "\n",
        "#       # Add texts, tables, and images\n",
        "#       # Check that text_summaries is not empty before adding\n",
        "#       if text_summaries:\n",
        "#           add_documents(retriever, text_summaries, texts)\n",
        "#       # Check that table_summaries is not empty before adding\n",
        "#       if table_summaries:\n",
        "#           add_documents(retriever, table_summaries, tab)\n",
        "#       # Check that image_summaries is not empty before adding\n",
        "#       if image_summaries:\n",
        "#           add_documents(retriever, image_summaries, img)\n",
        "\n",
        "#     return retriever\n",
        "\n",
        "# # from google.generativeai.embed_content import Embeddings\n",
        "# from google.generativeai.embedding import embed_content\n",
        "# from google.generativeai.embedding import embed_content_async\n",
        "\n",
        "# vectorstore = Chroma(\n",
        "#     collection_name=\"mm_rag\",\n",
        "#     embedding_function=Embeddings() )\n",
        "\n",
        "# # Create retriever\n",
        "# retriever_multi_vector_img = create_multi_vector_retriever(\n",
        "#     vectorstore,\n",
        "#     text_summaries,\n",
        "#     Text,\n",
        "#     table_summaries,\n",
        "#     Table,\n",
        "#     image_summaries,\n",
        "#     img_base64_list,\n",
        "# )\n",
        "\n",
        "import uuid\n",
        "from google.generativeai import embed_content\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "def create_multi_vector_retriever(vectorstore, text_summaries, texts, table_summaries, tables, image_summaries, images):\n",
        "    \"\"\"\n",
        "    Create retriever that indexes summaries, but returns raw images or texts.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the storage layer\n",
        "    store = InMemoryStore()\n",
        "    id_key = \"doc_id\"\n",
        "\n",
        "    # Create the multi-vector retriever\n",
        "    retriever = MultiVectorRetriever(\n",
        "        vectorstore=vectorstore,\n",
        "        docstore=store,\n",
        "        id_key=id_key,\n",
        "    )\n",
        "\n",
        "    # Helper function to add documents to the vectorstore and docstore\n",
        "    def add_documents(retriever, doc_summaries, doc_contents):\n",
        "        doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
        "\n",
        "        summary_docs = [\n",
        "            Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "            for i, s in enumerate(doc_summaries)\n",
        "        ]\n",
        "\n",
        "        retriever.vectorstore.add_documents(summary_docs)\n",
        "        retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
        "\n",
        "        # Add texts, tables, and images\n",
        "        # Check that text_summaries is not empty before adding\n",
        "        if text_summaries:\n",
        "            add_documents(retriever, text_summaries, texts)\n",
        "        # Check that table_summaries is not empty before adding\n",
        "        if table_summaries:\n",
        "            add_documents(retriever, table_summaries, tables)\n",
        "        # Check that image_summaries is not empty before adding\n",
        "        if image_summaries:\n",
        "            add_documents(retriever, image_summaries, images)\n",
        "\n",
        "    return retriever\n",
        "\n",
        "def get_embeddings(texts, model=\"models/text-embedding-004\", output_dimensionality=10):\n",
        "    \"\"\"\n",
        "    Use google.generativeai to generate embeddings for the provided texts.\n",
        "    \"\"\"\n",
        "    embeddings_result = embed_content(\n",
        "        model=model, content=texts, output_dimensionality=output_dimensionality\n",
        "    )\n",
        "    return embeddings_result\n",
        "\n",
        "# Create the vectorstore with embeddings\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"mm_rag\",\n",
        "    embedding_function=get_embeddings\n",
        ")\n",
        "\n",
        "# Example summaries and content (replace these with your actual data)\n",
        "text_summaries = [\"Summary of text 1\", \"Summary of text 2\"]\n",
        "texts = [\"Text 1\", \"Text 2\"]\n",
        "table_summaries = [\"Summary of table 1\", \"Summary of table 2\"]\n",
        "tables = [\"Table 1\", \"Table 2\"]\n",
        "image_summaries = [\"Summary of image 1\", \"Summary of image 2\"]\n",
        "img_base64_list = [\"base64_image_1\", \"base64_image_2\"]\n",
        "\n",
        "# Create retriever\n",
        "retriever_multi_vector_img = create_multi_vector_retriever(\n",
        "    vectorstore,\n",
        "    text_summaries,\n",
        "    texts,\n",
        "    table_summaries,\n",
        "    tables,\n",
        "    image_summaries,\n",
        "    img_base64_list\n",
        ")\n"
      ],
      "metadata": {
        "id": "3dMHI2TKDnMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_summaries"
      ],
      "metadata": {
        "id": "mPQRt2APDnTq",
        "outputId": "dca3457a-11e8-4b50-f459-364c8c94fbcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Two graphs show the training and validation accuracy and loss for an LSTM model over 50 epochs. The accuracy graph shows both training and validation accuracy increasing and converging, while the loss graph shows both training and validation loss decreasing and converging. This indicates the LSTM model is learning effectively from the data. \\n',\n",
              " 'Confusion matrix for an LSTM model, evaluating its performance in classifying between \"Healthy\" and \"Diseased\" states. The model shows high accuracy, with 1387 true positives for \"Healthy\" and 2499 true positives for \"Diseased\". There are very few false positives or false negatives. \\n',\n",
              " 'This image shows two line graphs. The left graph plots training and validation accuracy over epochs for an RNN model. The right graph plots training and validation loss over epochs for the same RNN model. Both graphs indicate good model performance with increasing accuracy and decreasing loss. \\n',\n",
              " \"A confusion matrix for an RNN model, showing the model's performance in classifying healthy and diseased cases. The matrix highlights a strong performance in correctly classifying diseased cases (2533 true positives) but a weaker performance in classifying healthy cases (1373 true positives and 15 false negatives). \\n\",\n",
              " 'This image shows two plots depicting the training and validation accuracy and loss of a BiLSTM model over 50 epochs. The accuracy plot shows both training and validation accuracy increasing and converging, while the loss plot shows training and validation loss decreasing and converging. This suggests the model is learning effectively and generalizing well to unseen data. \\n',\n",
              " 'Confusion matrix for a Bi-LSTM model, showing true vs. predicted labels for \"Healthy\" and \"Diseased\" categories. The model correctly identifies most \"Diseased\" cases (2529) but has a higher number of false negatives (6) compared to false positives (3). \\n',\n",
              " 'A table comparing the precision of different classifiers used with a BiLSTM network model. The classifiers are Support Vector Machine, k-Nearest Neighbors, Gradient Boosting, Random Forest, Decision Tree, and XGBoost. The precision ranges from 99.7637% to 99.9816%. \\n',\n",
              " 'A table comparing the sensitivity and specificity of three different neural network models: BiLSTM, RNN, and LSTM. BiLSTM achieves the highest sensitivity (99.96%) and specificity (99.78%), followed by RNN and LSTM. \\n',\n",
              " \"A table summarizing different papers on plant disease detection using machine learning. The table lists the paper's title, the methodology used, and the accuracy achieved.  Methodologies include spectral-based sensing, KNN, SVM, and random forest classifiers. \\n\",\n",
              " 'A table showing the precision of different classifiers when used with an LSTM network. The classifiers are Support Vector Machine, k-Nearest Neighbors, XGBoost, Gradient Boosting, Random Forest, and Decision Tree. The precision ranges from 99.8814% to 99.966%. \\n',\n",
              " 'A table comparing the precision of different classifiers when used with an RNN (Recurrent Neural Network). The classifiers listed are Support Vector Machine, k-Nearest Neighbors, XGBoost, Gradient Boosting, Decision Tree, Random Forest, and an unspecified classifier. The precision values range from 99.4113% to 99.9022%. \\n']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "!pip install langchain_community # Install the missing module\n",
        "import uuid\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "yquQa-OiDnQQ",
        "collapsed": true,
        "outputId": "26ad9989-a048-4c5a-d27f-01b2563f9be5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.11)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.25)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.94)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Downloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_community\n",
            "Successfully installed langchain_community-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "id": "G8MIt6Da3gKC",
        "outputId": "60b9a0df-18c6-4a07-8213-badcc07925c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.2)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.20.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_multi_vector_img"
      ],
      "metadata": {
        "id": "8EpcNUdqDnBG",
        "outputId": "1da6cb5e-920c-480b-e733-42c41ec03a51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiVectorRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7ec40bdec580>, docstore=<langchain_core.stores.InMemoryStore object at 0x7ec40915fe20>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import re\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def plt_img_base64(img_base64):\n",
        "    \"\"\"Disply base64 encoded string as image\"\"\"\n",
        "    # Create an HTML img tag with the base64 string as the source\n",
        "    image_html = f''\n",
        "    # Display the image by rendering the HTML\n",
        "    display(HTML(image_html))\n",
        "\n",
        "\n",
        "\n",
        "plt_img_base64(img_base64_list[1])"
      ],
      "metadata": {
        "id": "ajbC0XrvFLno",
        "outputId": "e6848e10-c4c2-4364-aaf8-6d3fdbd41ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_summaries[1]"
      ],
      "metadata": {
        "id": "cH0LADptFLkf",
        "outputId": "4bd10fe0-3e07-48dc-e745-d420c654402e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summary of image 2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def looks_like_base64(sb):\n",
        "    \"\"\"Check if the string looks like base64\"\"\"\n",
        "    return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\", sb) is not None\n"
      ],
      "metadata": {
        "id": "ij-IiI4oFLiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_image_data(b64data):\n",
        "    \"\"\"\n",
        "    Check if the base64 data is an image by looking at the start of the data\n",
        "    \"\"\"\n",
        "    image_signatures = {\n",
        "        b\"\\xFF\\xD8\\xFF\": \"jpg\",\n",
        "        b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\": \"png\",\n",
        "        b\"\\x47\\x49\\x46\\x38\": \"gif\",\n",
        "        b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
        "    }\n",
        "    try:\n",
        "        header = base64.b64decode(b64data)[:8]  # Decode and get the first 8 bytes\n",
        "        for sig, format in image_signatures.items():\n",
        "            if header.startswith(sig):\n",
        "                return True\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def resize_base64_image(base64_string, size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Resize an image encoded as a Base64 string\n",
        "    \"\"\"\n",
        "    # Decode the Base64 string\n",
        "    img_data = base64.b64decode(base64_string)\n",
        "    img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "    # Resize the image\n",
        "    resized_img = img.resize(size, Image.LANCZOS)\n",
        "\n",
        "    # Save the resized image to a bytes buffer\n",
        "    buffered = io.BytesIO()\n",
        "    resized_img.save(buffered, format=img.format)\n",
        "\n",
        "    # Encode the resized image to Base64\n",
        "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "def split_image_text_types(docs):\n",
        "    \"\"\"\n",
        "    Split base64-encoded images and texts\n",
        "    \"\"\"\n",
        "    b64_images = []\n",
        "    texts = []\n",
        "\n",
        "    for doc in docs:\n",
        "        # Check if the document is of type Document and extract page_content if so\n",
        "        if isinstance(doc, Document):\n",
        "            doc = doc.page_content\n",
        "        if looks_like_base64(doc) and is_image_data(doc):\n",
        "            doc = resize_base64_image(doc, size=(1300, 600))\n",
        "            b64_images.append(doc)\n",
        "        else:\n",
        "            texts.append(doc)\n",
        "\n",
        "    return {\"images\": b64_images, \"texts\": texts}\n",
        "\n",
        "\n",
        "def img_prompt_func(data_dict):\n",
        "    \"\"\"\n",
        "    Join the context into a single string\n",
        "    \"\"\"\n",
        "    #print(data_dict)\n",
        "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
        "    messages = []\n",
        "\n",
        "    # Adding image(s) to the messages if present\n",
        "    if data_dict[\"context\"][\"images\"]:\n",
        "        for image in data_dict[\"context\"][\"images\"]:\n",
        "            image_message = {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "            }\n",
        "            messages.append(image_message)\n",
        "\n",
        "    # Adding the text for analysis\n",
        "    text_message = {\n",
        "        \"type\": \"text\",\n",
        "        \"text\": (\n",
        "            \"You are a helpful assistant.\\n\"\n",
        "            \"You will be given a mixed info(s) .\\n\"\n",
        "            \"Use this information to provide relevant information to the user question. \\n\"\n",
        "            f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
        "            \"Text and / or tables:\\n\"\n",
        "            f\"{formatted_texts}\"\n",
        "        ),\n",
        "    }\n",
        "    messages.append(text_message)\n",
        "    return [HumanMessage(content=messages)]"
      ],
      "metadata": {
        "id": "u1mAyxP8FLgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "\n",
        "def multi_modal_rag_chain(retriever):\n",
        "    \"\"\"\n",
        "    Multi-modal RAG chain\n",
        "    \"\"\"\n",
        "\n",
        "    # Multi-modal LLM\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-pro\",\n",
        "        temperature=0,\n",
        "        max_tokens=None,\n",
        "        timeout=None,\n",
        "        max_retries=2,\n",
        "        # other params...\n",
        "    )\n",
        "\n",
        "\n",
        "    # RAG pipeline\n",
        "    chain = (\n",
        "        {\n",
        "            \"context\": retriever | RunnableLambda(split_image_text_types),\n",
        "            \"question\": RunnablePassthrough(),\n",
        "        }\n",
        "        | RunnableLambda(img_prompt_func)\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return chain\n",
        "\n",
        "\n",
        "# Create RAG chain\n",
        "chain_multimodal_rag = multi_modal_rag_chain(retriever_multi_vector_img)\n",
        "\n",
        "\n",
        "print(chain_multimodal_rag)\n",
        "\n",
        "# {\n",
        "#   context: MultiVectorRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x795d0c4e5cc0>, docstore=<langchain.storage.in_memory.InMemoryBaseStore object at 0x795cf4748910>)\n",
        "#            | RunnableLambda(split_image_text_types),\n",
        "#   question: RunnablePassthrough()\n",
        "# }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A8m0h1_2FLdq",
        "outputId": "75bc1b84-d625-401c-d496-6c50ef5e0a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first={\n",
            "  context: MultiVectorRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7ec40bdec580>, docstore=<langchain_core.stores.InMemoryStore object at 0x7ec40915fe20>)\n",
            "           | RunnableLambda(split_image_text_types),\n",
            "  question: RunnablePassthrough()\n",
            "} middle=[RunnableLambda(img_prompt_func), ChatGoogleGenerativeAI(model='models/gemini-1.5-pro', temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7ec409168220>, async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x7ec40916b7f0>, default_metadata=())] last=StrOutputParser()\n"
          ]
        }
      ]
    }
  ]
}